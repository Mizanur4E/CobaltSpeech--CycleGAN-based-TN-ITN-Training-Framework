Implemented different machine translation algorithm and model then evaluated them. 
Seqence is as follows:

1. simple encoder decoder based seq2seq model with bidirectional lstm layer (evaluated with and without context). "seq2seq with and without context.ipynb" contains the codes.
2. Attention Mechanism added to the seq2seq model and evaluated using context and without context
3. Applied GAN to observe adversarial loss effect on generator performance. "Using Simple GAN .ipynb" contains the corresponding code
4. Applied Cycle GAN that handle two generator normalization and inverse text normalization at the same time and evaluated the model. "Using Cycle GAN.py" contains the code
